# Diffusion training config with ARKit 51-blendshape face output
# Train with: python train.py --config configs/diffuser_arkit.yaml

is_train: True
ddp: False
stat: ts
root_path: ./
out_path: ./outputs/diffuser_arkit/
project: diffuser_arkit

# Evaluation model
e_path: weights/AESKConv_240_100.bin
eval_model: motion_representation
e_name: VAESKConv

# Data paths - BEAT for JSON face data
data_path: ./datasets/BEAT/beat_english_v0.2.1/beat_english_v0.2.1/
data_path_beat2: ./datasets/BEAT2/
data_path_1: ./datasets/hub/
pose_norm: True

# Model config
cfg: configs/diffuser_arkit_model.yaml

# Normalization paths
mean_pose_path: ./mean_std/beatx_2_330_mean.npy
std_pose_path: ./mean_std/beatx_2_330_std.npy
mean_trans_path: ./mean_std/beatx_2_trans_mean.npy
std_trans_path: ./mean_std/beatx_2_trans_std.npy

# VQ-VAE paths (body - pretrained)
vqvae_upper_path: ./ckpt/net_300000_upper.pth
vqvae_hands_path: ./ckpt/net_300000_hands.pth
vqvae_lower_path: ./ckpt/net_300000_lower.pth
vqvae_lower_trans_path: ./ckpt/net_300000_lower_trans.pth

# Face VQ-VAE (ARKit 51-dim) - train with train_face_vq_arkit.py first!
vqvae_face_path: ./ckpt/face_arkit_51.pth
use_arkit_face: True

use_trans: True
decay_epoch: 500
vqvae_squeeze_scale: 4
vqvae_latent_scale: 5

# VAE settings
vae_test_len: 32
vae_test_dim: 330
vae_test_stride: 20
vae_length: 240
vae_codebook_size: 256
vae_layer: 4
vae_grow: [1,1,2,1]
variational: False

# Data config
training_speakers: [2]
additional_data: False
cache_path: datasets/beat_cache/beat_arkit_diffuser/
dataset: beat_arkit
new_cache: True

# Motion config
ori_joints: beat_smplx_joints
tar_joints: beat_smplx_full
pose_rep: smplxflame_30
pose_fps: 30
rot6d: True
pre_frames: 4
pose_dims: 330
pose_length: 128
stride: 20
test_length: 128
m_fix_pre: False

# Audio config
audio_rep: onset+amplitude
audio_sr: 16000
audio_fps: 16000
audio_norm: False
audio_f: 256
audio_raw: None

# Text config
word_rep: textgrid
word_dims: 300
t_pre_encoder: fasttext

# Face config - ARKit 51 blendshapes!
facial_rep: arkit_51
facial_dims: 51
facial_norm: False
facial_f: 0

# Speaker config
id_rep: onehot
speaker_f: 0

# Training config
batch_size: 64
lr_base: 2e-4
trainer: diffuser_arkit
rec_weight: 1
grad_norm: 0.99
epochs: 500
test_period: 20

# GPU
gpus: [0]
seed: 42
val_period: 20
output_dir: ./outputs/
wandb_project: diffuser_arkit
